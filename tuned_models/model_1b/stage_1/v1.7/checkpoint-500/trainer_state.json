{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.03846005922849121,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0007692011845698242,
      "grad_norm": 0.7781069278717041,
      "learning_rate": 4.5e-06,
      "loss": 1.6803,
      "step": 10
    },
    {
      "epoch": 0.0015384023691396484,
      "grad_norm": 1.2901397943496704,
      "learning_rate": 9.5e-06,
      "loss": 1.9857,
      "step": 20
    },
    {
      "epoch": 0.002307603553709473,
      "grad_norm": 1.4041519165039062,
      "learning_rate": 1.45e-05,
      "loss": 1.8281,
      "step": 30
    },
    {
      "epoch": 0.003076804738279297,
      "grad_norm": 1.214382529258728,
      "learning_rate": 1.9500000000000003e-05,
      "loss": 1.7926,
      "step": 40
    },
    {
      "epoch": 0.0038460059228491213,
      "grad_norm": 1.028637170791626,
      "learning_rate": 2.45e-05,
      "loss": 1.7401,
      "step": 50
    },
    {
      "epoch": 0.004615207107418946,
      "grad_norm": 0.8147913813591003,
      "learning_rate": 2.95e-05,
      "loss": 1.7816,
      "step": 60
    },
    {
      "epoch": 0.005384408291988769,
      "grad_norm": 0.9585384130477905,
      "learning_rate": 3.45e-05,
      "loss": 1.7737,
      "step": 70
    },
    {
      "epoch": 0.006153609476558594,
      "grad_norm": 1.174300193786621,
      "learning_rate": 3.9500000000000005e-05,
      "loss": 1.6311,
      "step": 80
    },
    {
      "epoch": 0.006922810661128418,
      "grad_norm": 1.0646001100540161,
      "learning_rate": 4.4500000000000004e-05,
      "loss": 1.4104,
      "step": 90
    },
    {
      "epoch": 0.007692011845698243,
      "grad_norm": 0.9875959753990173,
      "learning_rate": 4.9500000000000004e-05,
      "loss": 1.4265,
      "step": 100
    },
    {
      "epoch": 0.008461213030268066,
      "grad_norm": 2.287405252456665,
      "learning_rate": 4.996511898302457e-05,
      "loss": 1.3925,
      "step": 110
    },
    {
      "epoch": 0.009230414214837892,
      "grad_norm": 1.182249665260315,
      "learning_rate": 4.992636229749632e-05,
      "loss": 1.5122,
      "step": 120
    },
    {
      "epoch": 0.009999615399407715,
      "grad_norm": 0.7786316275596619,
      "learning_rate": 4.988760561196807e-05,
      "loss": 1.4988,
      "step": 130
    },
    {
      "epoch": 0.010768816583977539,
      "grad_norm": 2.994170665740967,
      "learning_rate": 4.9848848926439814e-05,
      "loss": 1.7282,
      "step": 140
    },
    {
      "epoch": 0.011538017768547364,
      "grad_norm": 0.9385067224502563,
      "learning_rate": 4.981009224091156e-05,
      "loss": 1.4814,
      "step": 150
    },
    {
      "epoch": 0.012307218953117188,
      "grad_norm": 1.9206303358078003,
      "learning_rate": 4.9771335555383306e-05,
      "loss": 1.4784,
      "step": 160
    },
    {
      "epoch": 0.013076420137687013,
      "grad_norm": 1.3056221008300781,
      "learning_rate": 4.973257886985505e-05,
      "loss": 1.489,
      "step": 170
    },
    {
      "epoch": 0.013845621322256836,
      "grad_norm": 1.3418700695037842,
      "learning_rate": 4.96938221843268e-05,
      "loss": 1.5496,
      "step": 180
    },
    {
      "epoch": 0.01461482250682666,
      "grad_norm": 1.3645671606063843,
      "learning_rate": 4.965506549879855e-05,
      "loss": 1.6467,
      "step": 190
    },
    {
      "epoch": 0.015384023691396485,
      "grad_norm": 1.6269608736038208,
      "learning_rate": 4.961630881327029e-05,
      "loss": 1.5552,
      "step": 200
    },
    {
      "epoch": 0.01615322487596631,
      "grad_norm": 1.535305142402649,
      "learning_rate": 4.957755212774204e-05,
      "loss": 1.4812,
      "step": 210
    },
    {
      "epoch": 0.016922426060536132,
      "grad_norm": 0.8319595456123352,
      "learning_rate": 4.9538795442213784e-05,
      "loss": 1.457,
      "step": 220
    },
    {
      "epoch": 0.017691627245105958,
      "grad_norm": 1.2536147832870483,
      "learning_rate": 4.950003875668553e-05,
      "loss": 1.5762,
      "step": 230
    },
    {
      "epoch": 0.018460828429675783,
      "grad_norm": 1.5817807912826538,
      "learning_rate": 4.946128207115728e-05,
      "loss": 1.5203,
      "step": 240
    },
    {
      "epoch": 0.019230029614245605,
      "grad_norm": 0.850987434387207,
      "learning_rate": 4.942252538562903e-05,
      "loss": 1.5055,
      "step": 250
    },
    {
      "epoch": 0.01999923079881543,
      "grad_norm": 1.0967743396759033,
      "learning_rate": 4.938376870010077e-05,
      "loss": 1.5037,
      "step": 260
    },
    {
      "epoch": 0.020768431983385256,
      "grad_norm": 1.4089781045913696,
      "learning_rate": 4.934501201457252e-05,
      "loss": 1.5862,
      "step": 270
    },
    {
      "epoch": 0.021537633167955077,
      "grad_norm": 1.072658896446228,
      "learning_rate": 4.930625532904426e-05,
      "loss": 1.4732,
      "step": 280
    },
    {
      "epoch": 0.022306834352524903,
      "grad_norm": 0.9401404857635498,
      "learning_rate": 4.9267498643516006e-05,
      "loss": 1.4936,
      "step": 290
    },
    {
      "epoch": 0.023076035537094728,
      "grad_norm": 1.1491942405700684,
      "learning_rate": 4.9228741957987755e-05,
      "loss": 1.5463,
      "step": 300
    },
    {
      "epoch": 0.02384523672166455,
      "grad_norm": 1.3242032527923584,
      "learning_rate": 4.91899852724595e-05,
      "loss": 1.5441,
      "step": 310
    },
    {
      "epoch": 0.024614437906234375,
      "grad_norm": 1.2188971042633057,
      "learning_rate": 4.915122858693125e-05,
      "loss": 1.3649,
      "step": 320
    },
    {
      "epoch": 0.0253836390908042,
      "grad_norm": 1.334431767463684,
      "learning_rate": 4.9112471901403e-05,
      "loss": 1.5615,
      "step": 330
    },
    {
      "epoch": 0.026152840275374026,
      "grad_norm": 0.659655749797821,
      "learning_rate": 4.907371521587474e-05,
      "loss": 1.5342,
      "step": 340
    },
    {
      "epoch": 0.026922041459943848,
      "grad_norm": 1.204966425895691,
      "learning_rate": 4.9034958530346484e-05,
      "loss": 1.4826,
      "step": 350
    },
    {
      "epoch": 0.027691242644513673,
      "grad_norm": 0.9302323460578918,
      "learning_rate": 4.8996201844818234e-05,
      "loss": 1.5247,
      "step": 360
    },
    {
      "epoch": 0.028460443829083498,
      "grad_norm": 1.3576728105545044,
      "learning_rate": 4.8957445159289977e-05,
      "loss": 1.6284,
      "step": 370
    },
    {
      "epoch": 0.02922964501365332,
      "grad_norm": 1.5610566139221191,
      "learning_rate": 4.8918688473761726e-05,
      "loss": 1.5064,
      "step": 380
    },
    {
      "epoch": 0.029998846198223145,
      "grad_norm": 1.2350311279296875,
      "learning_rate": 4.8879931788233476e-05,
      "loss": 1.5145,
      "step": 390
    },
    {
      "epoch": 0.03076804738279297,
      "grad_norm": 1.5428472757339478,
      "learning_rate": 4.884117510270522e-05,
      "loss": 1.6274,
      "step": 400
    },
    {
      "epoch": 0.03153724856736279,
      "grad_norm": 1.3592116832733154,
      "learning_rate": 4.880241841717696e-05,
      "loss": 1.4991,
      "step": 410
    },
    {
      "epoch": 0.03230644975193262,
      "grad_norm": 1.1611053943634033,
      "learning_rate": 4.876366173164871e-05,
      "loss": 1.508,
      "step": 420
    },
    {
      "epoch": 0.03307565093650244,
      "grad_norm": 1.0806632041931152,
      "learning_rate": 4.8724905046120455e-05,
      "loss": 1.3969,
      "step": 430
    },
    {
      "epoch": 0.033844852121072265,
      "grad_norm": 0.5994410514831543,
      "learning_rate": 4.8686148360592204e-05,
      "loss": 1.3936,
      "step": 440
    },
    {
      "epoch": 0.034614053305642094,
      "grad_norm": 0.9304614663124084,
      "learning_rate": 4.8647391675063954e-05,
      "loss": 1.4542,
      "step": 450
    },
    {
      "epoch": 0.035383254490211916,
      "grad_norm": 1.3779747486114502,
      "learning_rate": 4.86086349895357e-05,
      "loss": 1.4546,
      "step": 460
    },
    {
      "epoch": 0.03615245567478174,
      "grad_norm": 1.1688258647918701,
      "learning_rate": 4.856987830400744e-05,
      "loss": 1.4007,
      "step": 470
    },
    {
      "epoch": 0.036921656859351566,
      "grad_norm": 1.2193689346313477,
      "learning_rate": 4.853112161847919e-05,
      "loss": 1.5144,
      "step": 480
    },
    {
      "epoch": 0.03769085804392139,
      "grad_norm": 1.2909737825393677,
      "learning_rate": 4.849236493295093e-05,
      "loss": 1.5646,
      "step": 490
    },
    {
      "epoch": 0.03846005922849121,
      "grad_norm": 0.8283432126045227,
      "learning_rate": 4.845360824742268e-05,
      "loss": 1.4358,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 13001,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1251603729494016.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
